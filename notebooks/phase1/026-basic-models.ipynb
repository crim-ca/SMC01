{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "posted-confidence",
   "metadata": {},
   "source": [
    "An attempt at very basic models on the post processing data.\n",
    "1. Linear regression\n",
    "2. Simple station embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv('DATA_DIR'))\n",
    "INPUT_DIR = DATA_DIR / '2021-03-17-ppdataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(INPUT_DIR / '*.parquet')\n",
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step_td'] = pd.to_timedelta(df['step'], unit='S')\n",
    "df['valid'] = df['date'] + df['step_td']\n",
    "df['error_2t'] = df['gdps_2t'] - df['obs_2t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_component = np.sin((df.date.dt.dayofyear / 366) * 2*np.pi ).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_component = np.sin((df['valid'].dt.hour / 24) * 2*np.pi).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_component = (df['step'] / (237 * 60 * 60)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_embedding = torch.empty((len(df), 3))\n",
    "temporal_embedding[:,0] = torch.from_numpy(yearly_component)\n",
    "temporal_embedding[:,1] = torch.from_numpy(daily_component)\n",
    "temporal_embedding[:,2] = torch.from_numpy(step_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_embedding[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_embedding.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['station'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = sorted(list(set(df['station'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = df['station'].astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_embedding = torch.from_numpy(station_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c.startswith('gdps')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.empty((len(df), len(feature_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(feature_cols):\n",
    "    features[:,i] = torch.from_numpy(df[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = torch.from_numpy(df['error_2t'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherInMemoryDataset:\n",
    "    def __init__(self, station_embedding, temporal_embedding, features, y):\n",
    "        self.station = station_embedding\n",
    "        self.temporal = temporal_embedding\n",
    "        self.x = features\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.station[idx], self.temporal[idx], self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WeatherInMemoryDataset(torch.from_numpy(station_ids).long(), temporal_embedding, features, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_embedding.float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=20000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumbWeatherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.station_embedding = nn.Parameter(torch.randn(1678, 128, requires_grad=True).double() / 128)\n",
    "        self.temporal_embedding = nn.Linear(in_features=3, out_features=32).double()\n",
    "        \n",
    "        self.kernel = nn.Parameter(torch.randn(128, 32, 20, requires_grad=True).double() / (128*32))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(128, 32, requires_grad=True)).double()\n",
    "        self.scale = nn.Parameter(torch.randn(128, 32, requires_grad=True)).double()\n",
    "        \n",
    "    def forward(self, station_code, temporal_code, x):\n",
    "        station = self.station_embedding[station_code]\n",
    "        temporal = self.temporal_embedding(temporal_code)\n",
    "        \n",
    "        pred = torch.einsum('ijk,bi,bj,bk->b',self.kernel, station, temporal, x)\n",
    "        bias = torch.einsum('bi,ij,bj->b', station, self.bias, temporal)\n",
    "        scale = torch.einsum('bi,ij,bj->b', station, self.scale, temporal)\n",
    "        \n",
    "        return pred * scale + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DumbWeatherModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_code, temporal_code, x, y = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for b in loader:\n",
    "        \n",
    "        station_code, temporal_code, x, y = b\n",
    "        \n",
    "        y_hat = model(station_code, temporal_code.double(), x.double())\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.station_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.temporal_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.temporal_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-young",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
