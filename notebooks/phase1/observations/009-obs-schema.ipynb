{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWOB_DIR = ''\n",
    "SWOB_FILE = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re\n",
    "import xml.dom.minidom\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv('DATA_DIR'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boot up slurm cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    cores=12,\n",
    "    processes=6,\n",
    "    memory='128G',\n",
    "    env_extra=['source ~/.bash_profile','conda activate smc01'],\n",
    "    name='smc01-dask',\n",
    "    local_directory=DATA_DIR / 'dask',\n",
    "    walltime='9:00:00',\n",
    "    job_mem='12G',\n",
    "    job_cpu=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=6)  # Scale to two working nodes as configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load observation files in a dask bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_dict(obs_xml_string):\n",
    "    obs_data = xml.dom.minidom.parseString(obs_xml_string)\n",
    "    metadata = obs_data.getElementsByTagName('identification-elements')[0]\n",
    "\n",
    "    metadata_dict = {}\n",
    "\n",
    "    for element in metadata.childNodes:\n",
    "        variable = element.attributes['name'].value\n",
    "        value = element.attributes['value'].value\n",
    "        metadata_dict[variable] = value\n",
    "        \n",
    "    obs_dict = {}\n",
    "\n",
    "    elements = obs_data.getElementsByTagName('elements')\n",
    "    \n",
    "    if elements:\n",
    "        for element in elements[0].childNodes:\n",
    "            variable = element.attributes['name'].value\n",
    "            value = element.attributes['value'].value\n",
    "            obs_dict[variable] = value\n",
    "        \n",
    "    return {**metadata_dict, **obs_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWOB_PATH = pathlib.Path(SWOB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swob_files = list(SWOB_PATH.glob('**/*.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(swob_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_swob_files = [x for x in swob_files if 'minute' not in x.stem] # Keep only hourly swob files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hourly_swob_files) / len(swob_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OBS = len(hourly_swob_files)\n",
    "N_OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = db.read_text(hourly_swob_files, files_per_partition=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts = bag.map(string_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts = obs_dicts.repartition(partition_size='10MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts = obs_dicts.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce to count keys\n",
    "\n",
    "Check what keys are contained in the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_key_count(d):\n",
    "    return {k: 1 for k in d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_count_dicts(counts1, counts2):\n",
    "    counts = counts1\n",
    "    \n",
    "    for k, val in counts2.items():\n",
    "        if k in counts:\n",
    "            counts[k] += val\n",
    "        else:\n",
    "            counts[k] = val\n",
    "            \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keys(bag):\n",
    "    return bag.map(dict_to_key_count).fold(merge_count_dicts).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_counts = count_keys(obs_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_key_report(counts, filter_re='.*', total=N_OBS):\n",
    "    \n",
    "    compiled_filter = re.compile(filter_re)\n",
    "    for k, v in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        if compiled_filter.match(k):\n",
    "            print('{:50}{:7} ({:6.1%})'.format(k, v, v / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_key_report(computed_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "obs_dicts.filter(lambda x: 'tc_id' in x).pluck('tc_id').frequencies().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrections\n",
    "\n",
    "Le champ \"cor\" semble servir à indiquer des corrections, mais puisqu'on parle de moins de .5% des observations, on va juste ignorer le champ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts.filter(lambda x: 'cor' in x).pluck('cor').frequencies().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station type\n",
    "\n",
    "Certaines stations indiquent un type de station.\n",
    "Le type 18 semble impliquer une bouée marine au lieu d'une station terrestre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts.filter(lambda x: ('stn_typ' in x)).pluck('stn_typ').frequencies().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les observations qui ont un ICAO_STN_ID ont de quoi à faire avec l'aviation. Elles ont un profil de variables différent (plus de champs disponibles tout le temps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_obs = obs_dicts.filter(lambda x: 'icao_stn_id' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_airport_obs = airport_obs.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_obs.pluck('stn_typ').frequencies().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_counts = airport_obs.map(dict_to_key_count).fold(merge_count_dicts).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_key_report(airport_counts, total=n_airport_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les observations avec un icao id proviennent de Nav Canada et de la défense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_obs.pluck('data_attrib_not').frequencies().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract fields from dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(dicts):\n",
    "    merged = dicts[0].copy()\n",
    "    for d in dicts:\n",
    "        merged.update(d)\n",
    "        \n",
    "    return merged\n",
    "\n",
    "class Extractor:\n",
    "    \"\"\"Used to extract records from observation dictionary.\"\"\"\n",
    "    COLUMNS = {}\n",
    "    \n",
    "    def schema(self):\n",
    "        return self.COLUMNS\n",
    "    \n",
    "    def __call__(self, obs):\n",
    "        return {k: self.process_value(k, obs[k]) for k in self.COLUMNS if k in obs}\n",
    "    \n",
    "    def process_value(self, key, value):\n",
    "        if value == 'MSNG':\n",
    "            return None\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    \n",
    "class CompositeExtractor:\n",
    "    def __init__(self, extractors):\n",
    "        self.extractors = extractors\n",
    "        \n",
    "    def schema(self):\n",
    "        return merge_dicts([e.schema() for e in self.extractors])\n",
    "    \n",
    "    def __call__(self, obs):\n",
    "        return merge_dicts([e(obs) for e in self.extractors])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataExtractor(Extractor):\n",
    "    OBLIGATORY_COLUMNS = {\n",
    "        'date_tm': 'datetime64[ns]',\n",
    "        'stn_nam': 'object',\n",
    "        'stn_elev': 'float',\n",
    "        'msc_id': 'object',\n",
    "        'lat': 'float',\n",
    "        'long': 'float',\n",
    "    }\n",
    "    \n",
    "    OPTIONAL_COLUMNS = {\n",
    "        'data_pvdr': 'object',\n",
    "        'wmo_synop_id': 'object',\n",
    "        'tc_id': 'object',\n",
    "        'icao_stn_id': 'object'\n",
    "    }\n",
    "    \n",
    "    COLUMNS = {**OBLIGATORY_COLUMNS, **OPTIONAL_COLUMNS}\n",
    "    \n",
    "    def __call__(self, obs):\n",
    "        for k in self.OBLIGATORY_COLUMNS:\n",
    "            if k not in obs:\n",
    "                raise ValueError('Obligatory metadata {} not found in observation'.format(k))\n",
    "        return super().__call__(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts.map(MetadataExtractor()).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataExtractor().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Température"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Répartition des champs de température"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_key_report(computed_counts, filter_re='.*temp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemperatureExtractor(Extractor):\n",
    "    AIR_TEMP_SOURCES = [\n",
    "        'air_temp',\n",
    "        'air_temp_1',\n",
    "        'avg_air_temp_pst10mts',\n",
    "        'avg_air_temp_pst1hr',\n",
    "    ]\n",
    "    \n",
    "    COLUMNS = {\n",
    "        'max_air_temp_pst1hr': 'float',\n",
    "        'mar_air_temp_pst6hrs': 'float',\n",
    "        'max_air_temp_pst24hrs': 'float',\n",
    "        'min_air_temp_pst1hr': 'float',\n",
    "        'min_air_temp_pst6hrs': 'float',\n",
    "        'min_air_temp_pst24hrs': 'float',\n",
    "    }\n",
    "    \n",
    "    def __call__(self, obs):\n",
    "        extracted = super().__call__(obs)\n",
    "        \n",
    "        for s in self.AIR_TEMP_SOURCES:\n",
    "            if s in obs:\n",
    "                extracted['air_temp'] = self.process_value(s, obs[s])\n",
    "                extracted['air_temp_source'] = s\n",
    "        \n",
    "        return extracted\n",
    "        \n",
    "    def schema(self):\n",
    "        parent = super().schema()\n",
    "        parent['air_temp'] = 'float'\n",
    "        parent['air_temp_source'] = 'object'\n",
    "        \n",
    "        return parent\n",
    "\n",
    "def get_temp(obs):\n",
    "    \"\"\"Read inst. air temperature from observation. If not directly provided,\n",
    "    use alternate fields as a next best guess. Also, fetch air temperature statistics\n",
    "    if available.\"\"\"\n",
    "    temp_dict = {}\n",
    "    \n",
    "    temp_keys = [\n",
    "        'air_temp', \n",
    "        'air_temp_1', \n",
    "        'avg_air_temp_pst10mts', \n",
    "        'avg_air_temp_pst1hr'\n",
    "    ]\n",
    "    \n",
    "    for k in temp_keys:\n",
    "        if k in obs and obs[k] != 'MSNG':\n",
    "            temp_dict['air_temp_source'], temp_dict['air_temp'] = k, obs[k]\n",
    "            break\n",
    "            \n",
    "    for metric, duration in itertools.product(['max', 'min'], ['pst1hr', 'pst6hrs', 'pst24hrs']):\n",
    "        k = '{}_air_temp_{}'.format(metric, duration)\n",
    "        if k in obs and obs[k] != 'MSNG':\n",
    "            temp_dict[k] = obs[k]\n",
    "        \n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = obs_dicts.map(TemperatureExtractor()).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_key_report(no_temp_counts, total=no_temp_n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_temp.pluck('data_pvdr').frequencies().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bc = obs_dicts.filter(lambda x: 'data_pvdr' not in x or x['data_pvdr'] != 'BC-ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bc.count().compute() / N_OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bc_count = count_keys(no_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_key_report(no_bc_count, filter_re='.*temp.*', total=no_bc.count().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_temp_keys(d):\n",
    "    base_dict = {k: d[k] for k in ['msc_id']}\n",
    "    return {**{k: d[k] for k in d if 'temp' in k}, **base_dict}\n",
    "\n",
    "def msng_to_nan(d):\n",
    "    return {k: None if d[k] == 'MSNG' else d[k] for k in d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts.map(take_temp_keys).take(1, npartitions=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_keys = obs_dicts.map(take_temp_keys).map(dict_to_key_count).fold(merge_count_dicts).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_meta = dd.utils.make_meta([(k, 'f8') for k in temp_keys if k != 'msc_id'] + [('msc_id', 'string')])\n",
    "temp_df = obs_dicts.map(take_temp_keys).map(msng_to_nan).to_dataframe(meta=temp_meta).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.groupby('msc_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[temp_df['']].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts.map(get_temp).filter(lambda x: 'air_temp' in x).pluck('air_temp_source').frequencies().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = obs_dicts.map(get_temp).filter(lambda x: 'air_temp' in x).pluck('air_temp').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = np.array(temps, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts.map(get_temp).filter(lambda x: 'air_temp' in x).filter(lambda x: float(x['air_temp']) < -600).take(1, npartitions=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_key_report(computed_counts, filter_re='.*wnd.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindExtractor(Extractor):\n",
    "    COLUMNS = {\n",
    "        'avg_wnd_dir_10m_pst10mts': 'float',\n",
    "        'avg_wnd_spd_10m_pst10mts': 'float',\n",
    "        'avg_wnd_dir_10m_pst2mts': 'float',\n",
    "        'avg_wnd_spd_10m_pst2mts': 'float',\n",
    "        'avg_wnd_dir_10m_pst1hr': 'float',\n",
    "        'avg_wnd_spd_10m_pst1hr': 'float',\n",
    "        'pk_wnd_rmk': 'object',\n",
    "        'max_wnd_spd_10m_pst1hr': 'float',\n",
    "        'wnd_dir_10m_pst1hr_max_spd': 'float',\n",
    "        'max_wnd_gst_spd_10m_pst10mts': 'float',\n",
    "        'wnd_dir_10m_pst10mts_max_spd': 'float',              \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['date_tm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PressureExtractor(Extractor):\n",
    "    COLUMNS = {\n",
    "        'altmetr_setng': 'float',\n",
    "        'mslp': 'float',\n",
    "        'pres_tend_amt_pst3hrs': 'float',\n",
    "        'pres_tend_char_pst3hrs': 'float',\n",
    "        'stn_pres': 'float',\n",
    "    }\n",
    "    \n",
    "    def process_value(self, key, value):\n",
    "        pre_processed = super().process_value(key, value)\n",
    "        \n",
    "        if pre_processed:\n",
    "            value = float(pre_processed)\n",
    "\n",
    "            if value > 0.0:\n",
    "                return value\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humidité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Précipitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visibilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = CompositeExtractor([WindExtractor(), MetadataExtractor(), PressureExtractor()])\n",
    "df = obs_dicts.map(extractor).to_dataframe(meta=extractor.schema()).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dicts.map(extractor).random_sample(0.001).take(1, npartitions=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='stn_elev', y='stn_pres', data=df[df['data_pvdr'] == 'NAV CANADA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stn_pres'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
