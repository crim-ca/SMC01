{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.distributed\n",
    "import dask.dataframe as dd\n",
    "import dask_jobqueue\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=['source ~/.bash_profile','conda activate smc01'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=2)  # Scale to two working nodes as configured.\n",
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv('DATA_DIR'))\n",
    "INPUT_DIR = DATA_DIR / '2021-03-17-ppdataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [f for f in pathlib.Path(INPUT_DIR).iterdir() if f.suffix == '.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = ['station', 'latitude', 'longitude', 'elevation', 'date', 'step', 'obs_2t', 'gdps_2t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(csv_files[0:100], usecols=view, converters={\n",
    "    'date': pd.to_datetime,\n",
    "    'step': pd.to_timedelta,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(INPUT_DIR + '/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abs_error_2t'] = np.abs(df['gdps_2t'] - df['obs_2t'])\n",
    "df['error_2t'] = df['gdps_2t'] - df['obs_2t']\n",
    "df['step_hours'] = df['step'] / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['error_2t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c.startswith('gdps')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((len(df), len(feature_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(feature_cols):\n",
    "    X[:,i] = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[df['date'] <= '2019-01-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = df[df['date'] > '2019-01-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.empty((len(train_set), len(feature_cols)))\n",
    "val_Y = np.empty((len(val_set), len(feature_cols)))\n",
    "for i, col in enumerate(feature_cols):\n",
    "    train_X[:,i] = train_set[col]\n",
    "    val_Y[:,i] = val_set[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(train_set['error_2t'])\n",
    "val_y = np.array(val_set['error_2t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-quebec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
