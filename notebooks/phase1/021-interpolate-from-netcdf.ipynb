{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate from netCDF\n",
    "\n",
    "The purpose of this notebook is to perform the same interpolation that is found in 017-interpolate-at-stations.ipynb.\n",
    "This time, however, we start from netcdf files generated with 019-prepare-dataset-pygrib.ipynb instead of raw grib files.\n",
    "The hypothesis is that XArray will be much happier working from netCDF that grib.\n",
    "\n",
    "The plan is to\n",
    "1. Load the netCDF datacube.\n",
    "2. Load station coordinates.\n",
    "3. Interpolate at stations.\n",
    "4. Generate a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import datetime\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pygrib\n",
    "import pymongo\n",
    "import seaborn as sns\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=[\n",
    "        'source ~/.bash_profile','conda activate smc01'],\n",
    "    name='smc01-dask',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the netCDF datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv('DATA_DIR'))\n",
    "GDPS_DIR = DATA_DIR / '2021-02-10-one-month-more-vars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps_path = pathlib.Path(GDPS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps_files = sorted([f for f in gdps_path.glob(\"*.nc\")])\n",
    "gdps_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = {}\n",
    "for f in gdps_files:\n",
    "    pass_string = f.stem[5:15]\n",
    "    \n",
    "    pass_files = passes.get(pass_string, [])\n",
    "    pass_files.append(f)\n",
    "    \n",
    "    passes[pass_string] = pass_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nest_filenames(files):\n",
    "    passes = {}\n",
    "    for f in files:\n",
    "        pass_name = f.stem[5:15]\n",
    "        \n",
    "        pass_list = passes.get(pass_name, [])\n",
    "        pass_list.append(f)\n",
    "        passes[pass_name] = pass_list\n",
    "        \n",
    "    sorted_passes = sorted(passes.keys())\n",
    "        \n",
    "    return [passes[k] for k in sorted_passes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_gdps = nest_filenames(gdps_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_vars(dataset):\n",
    "    to_drop = ['r_850', 'r_500']\n",
    "    \n",
    "    for var in to_drop:\n",
    "        if var in dataset:\n",
    "            dataset = dataset.drop(var)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps = xr.open_mfdataset(\n",
    "    nested_gdps, concat_dim=['time', 'step'], \n",
    "    combine='nested', parallel=True, compat='no_conflicts',\n",
    "    preprocess=drop_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = gdps.step.data.astype('timedelta64[h]')\n",
    "times = [datetime.datetime.utcfromtimestamp(x) for x in gdps.time.data.astype(datetime.datetime) // 1e9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = gdps.time.data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = deltas.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times = times + deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps = gdps.assign_coords(valid_time=xr.DataArray(valid_times, dims=('time', 'step')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load station coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URL = 'localhost'\n",
    "MONGO_PORT = 27017\n",
    "USERNAME = None\n",
    "PASSWORD = None\n",
    "ADMIN_DB = 'admin'\n",
    "DB = 'smc01_raw_obs_test'\n",
    "COLLECTION = 'iem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date = gdps.valid_time.min().data.item()\n",
    "begin_date = datetime.datetime.utcfromtimestamp(begin_date // 1e9)\n",
    "\n",
    "end_date = gdps.valid_time.max().data.item()\n",
    "end_date = datetime.datetime.utcfromtimestamp(end_date // 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = pymongo.MongoClient(host=MONGO_URL, port=MONGO_PORT, username=USERNAME, password=PASSWORD, authSource=ADMIN_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mongo_client.smc01_raw_obs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.iem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'valid': {\n",
    "        '$gte': begin_date,\n",
    "        '$lt': end_date\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = collection.distinct('station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_infos = []\n",
    "\n",
    "for station in stations:\n",
    "    one_obs = collection.find_one({'station': station})\n",
    "    station_infos.append({\n",
    "        'station': station,\n",
    "        'lat': one_obs['lat'],\n",
    "        'lon': one_obs['lon'],\n",
    "        'elevation': one_obs['elevation']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = pd.DataFrame(station_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Interpolate at stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations = gdps.interp({\n",
    "    'latitude': xr.DataArray(station_df['lat'], dims='station'),\n",
    "    'longitude': xr.DataArray(station_df['lon'], dims='station'),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations = at_stations.assign_coords(station=xr.DataArray(station_df['station'], dims='station'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations_compute = at_stations.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations_compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations_compute.to_netcdf(DATA_DIR / '2021-02-10-march-interpolated-at-stations.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations_compute.nbytes / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations_compute.valid_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = list(at_stations_compute.groupby('valid_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compute dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_of_station(station_name, begin_date, end_date):\n",
    "    return [\n",
    "        {\n",
    "            '$addFields': {\n",
    "                'minute': {\n",
    "                    '$minute': '$valid'\n",
    "                },\n",
    "                'hour': {\n",
    "                    '$hour': '$valid'\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$match': {\n",
    "                'minute': 0,\n",
    "                'station': station_name,\n",
    "                'valid': {\n",
    "                    '$gte': begin_date,\n",
    "                    '$lt': end_date\n",
    "                },\n",
    "                'hour': {\n",
    "                    '$in': [0, 3, 6, 9, 12, 15, 18, 21]\n",
    "                },\n",
    "                'tmpf': {\n",
    "                    '$exists': True,\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_obs_of_station = list(collection.aggregate(pipeline_of_station('CYUL', begin_date, end_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_obs_of_station[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reports_of_station(station_name, begin_date, end_date, model_at_station):\n",
    "\n",
    "    by_valid = {valid_time: group for valid_time, group in model_at_station.groupby('valid_time')}\n",
    "\n",
    "    reports = []\n",
    "    \n",
    "    station_obs = list(\n",
    "        collection.aggregate(\n",
    "            pipeline_of_station(station_name, begin_date, end_date)))\n",
    "\n",
    "    for obs in station_obs:\n",
    "        obs_time = np.datetime64(obs['valid'], 'ns')\n",
    "        obs_temp = (obs['tmpf'] - 32) * (5/9) \n",
    "\n",
    "        if obs_time in by_valid:\n",
    "            group_of_time = by_valid[obs_time]\n",
    "\n",
    "            for i in range(len(group_of_time.stacked_time_step)):\n",
    "                date = datetime.datetime.utcfromtimestamp(group_of_time.time[i].item() / 1e9)\n",
    "                \n",
    "                step = datetime.timedelta(hours=group_of_time.step[i].item())\n",
    "                temp = group_of_time['2t'][i].item() - 273.15\n",
    "                dewpoint = group_of_time['2d'][i].item() - 273.15\n",
    "\n",
    "                report = {\n",
    "                    'station': obs['station'],\n",
    "                    'valid': date + step,\n",
    "                    'lat': obs['lat'],\n",
    "                    'lon': obs['lon'],\n",
    "                    'elevation': obs['elevation'],\n",
    "                    'obs_2t': obs_temp,\n",
    "                    'date': date,\n",
    "                    'step': step,\n",
    "                    'gdps_2d': dewpoint,\n",
    "                    'gdps_2t': temp,\n",
    "                }\n",
    "                \n",
    "                if 'dwpt' in obs:\n",
    "                    report['obs_2d'] = (obs['dwpt'] - 32) * (5/9)\n",
    "                else:\n",
    "                    report['obs_2d'] = np.nan\n",
    "                \n",
    "                if 'sknt' in obs:\n",
    "                    report['obs_10si'] = obs['sknt'] / 1.94384\n",
    "                else:\n",
    "                    report['obs_10si'] = np.nan\n",
    "                    \n",
    "                if 'mslp' in obs:\n",
    "                    report['obs_prmsl'] = obs['mslp']\n",
    "                else:\n",
    "                    report['obs_prmsl'] = np.nan\n",
    "\n",
    "                \n",
    "                obs_target_pairs = [\n",
    "                    ('drct', 'obs_10wdir'),\n",
    "                    ('relh', 'obs_2r'),\n",
    "                ]\n",
    "                \n",
    "                for obs_key, target in obs_target_pairs:\n",
    "                    if obs_key in obs:\n",
    "                        report[target] = obs[obs_key]\n",
    "                    else:\n",
    "                        report[target] = np.nan\n",
    "                        \n",
    "                report['gdps_prmsl'] = group_of_time['prmsl'][i].item() / 100.\n",
    "\n",
    "                for key in ['10si', '10wdir', '2r', 'hpbl', 'prate']:\n",
    "                    report['gdps_' + key] = group_of_time[key][i].item()\n",
    "\n",
    "                reports.append(report)\n",
    "\n",
    "    return pd.DataFrame(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_name = 'CYUL'\n",
    "model_at_station = at_stations_compute.sel(station=station_name)\n",
    "\n",
    "reports = compute_reports_of_station(station_name, begin_date, end_date, model_at_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports['step'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports['2t_square_error'] = (reports['gdps_2t'] - reports['obs_2t'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_step = reports.groupby('step').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='step', y='2t_square_error', data=reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_by_countion['CYUL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_valid[np.datetime64('2020-03-01T00:00:00.000000000')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Compute reports in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_obs = observations_by_station['CYUL']\n",
    "model_at_station = at_stations_compute.sel(station='CYUL')\n",
    "\n",
    "#reports = compute_reports_of_station(station_obs, model_at_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_reports_delayed = dask.delayed(compute_reports_of_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [begin_date + datetime.timedelta(days=i) for i in range((end_date - begin_date).days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(end_date - begin_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = (end_date - begin_date).days\n",
    "\n",
    "delayeds = []\n",
    "for s in station_df['station']:\n",
    "    \n",
    "    for i in range(n_days // 10):\n",
    "        begin_batch =  begin_date + datetime.timedelta(days=i * 10)\n",
    "        end_batch = begin_date + datetime.timedelta(days=(i + 1) * 10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        model_at_station = at_stations_compute.sel(station=s)\n",
    "\n",
    "        delayed = compute_reports_delayed(s, begin_batch, end_batch, model_at_station)\n",
    "        delayeds.append(delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_at_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_at_station.where(time >= begin_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(delayeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayeds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_obs = observations_by_station['CYUL'][0:10]\n",
    "model_at_station = at_stations_compute.sel(station='CYRL')\n",
    "sample = compute_reports_of_station('CYUL', begin_date, end_date, model_at_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = dd.from_delayed(delayeds, meta=sample, verify_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = big_df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['step'] = big_df['step'].dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_parquet(DATA_DIR / 'hdd_scratch/smc01/march.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = big_df.repartition(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df_compute = big_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df_compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['2t_squared_error'] = (big_df['gdps_2t'] - big_df['obs_2t'])**2\n",
    "big_df['2r_squared_error'] = (big_df['gdps_2r'] - big_df['obs_2r'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_step = big_df.groupby('step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_step_compute = by_step.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_step_compute['2t_rmse'] = np.sqrt(by_step_compute['2t_squared_error'])\n",
    "by_step_compute['2r_rmse'] = np.sqrt(by_step_compute['2r_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_step_compute = by_step_compute.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='step', y='2r_rmse', data=by_step_compute.iloc[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
