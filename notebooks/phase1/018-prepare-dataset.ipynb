{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "\n",
    "The purpose of this notebook is to prepare a statistical downscaling dataset\n",
    "using only Xarray to open grib files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask_jobqueue\n",
    "import dask.distributed\n",
    "import datetime\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import seaborn as sns\n",
    "import time\n",
    "import xarray as xr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv('DATA_DIR'))\n",
    "GDPS_DIR = DATA_DIR / '2021-02-02-one-week-sample/'\n",
    "\n",
    "MONGO_URL = 'localhost'\n",
    "MONGO_PORT = 27017\n",
    "USERNAME = None\n",
    "PASSWORD = None\n",
    "ADMIN_DB = 'admin'\n",
    "DB = 'smc01_raw_obs_test'\n",
    "COLLECTION = 'iem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=[\n",
    "        'source ~/.bash_profile','conda activate smc01'],\n",
    "    name='smc01-dask',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps_files = sorted(list(pathlib.Path(GDPS_DIR).glob('CMC_glb_latlon.24x.24_*.grib2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nest_filenames(files):\n",
    "    passes = {}\n",
    "    for f in files:\n",
    "        pass_name = f.stem[22:32]\n",
    "        \n",
    "        pass_list = passes.get(pass_name, [])\n",
    "        pass_list.append(f)\n",
    "        passes[pass_name] = pass_list\n",
    "        \n",
    "    sorted_passes = sorted(passes.keys())\n",
    "        \n",
    "    return [passes[k] for k in sorted_passes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_files = nest_filenames(gdps_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps = xr.open_mfdataset(\n",
    "    nested_files, engine='cfgrib', concat_dim=['time', 'step'], \n",
    "    combine='nested', parallel=True, compat='no_conflicts',\n",
    "    backend_kwargs={'filter_by_keys': {\n",
    "        'typeOfLevel': 'heightAboveGround',\n",
    "        'stepType': 'instant',\n",
    "}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps_surface = xr.open_mfdataset(\n",
    "    nested_files, engine='cfgrib', concat_dim=['time', 'step'], \n",
    "    combine='nested', parallel=True, compat='no_conflicts',\n",
    "    backend_kwargs={'filter_by_keys': {\n",
    "        'typeOfLevel': 'surface',\n",
    "        'stepType': 'instant',\n",
    "}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps_iso = xr.open_mfdataset(\n",
    "    nested_files, engine='cfgrib', concat_dim=['time', 'step'], \n",
    "    combine='nested', parallel=True, compat='no_conflicts',\n",
    "    backend_kwargs={'filter_by_keys': {\n",
    "        'typeOfLevel': 'isobaricInhPa',\n",
    "        'stepType': 'instant',\n",
    "}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fetch station coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date = gdps.valid_time.min().data.item()\n",
    "begin_date = datetime.datetime.utcfromtimestamp(begin_date // 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = gdps.valid_time.max().data.item()\n",
    "end_date = datetime.datetime.utcfromtimestamp(end_date // 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = pymongo.MongoClient(host=MONGO_URL, port=MONGO_PORT, username=USERNAME, password=PASSWORD, authSource=ADMIN_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mongo_client.smc01_raw_obs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.iem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'valid': {\n",
    "        '$gte': begin_date + datetime.timedelta(days=1),\n",
    "        '$lt': end_date\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = collection.distinct('station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_infos = []\n",
    "\n",
    "for station in stations:\n",
    "    one_obs = collection.find_one({'station': station})\n",
    "    station_infos.append({\n",
    "        'station': station,\n",
    "        'lat': one_obs['lat'],\n",
    "        'lon': one_obs['lon'],\n",
    "        'elevation': one_obs['elevation']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = pd.DataFrame(station_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Interpolate model at stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations = gdps.interp({\n",
    "    'latitude': xr.DataArray(station_df['lat'], dims='station'),\n",
    "    'longitude': xr.DataArray(station_df['lon'], dims='station'),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_stations = at_stations.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMC01",
   "language": "python",
   "name": "smc01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
