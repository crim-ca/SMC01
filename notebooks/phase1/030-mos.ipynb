{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "national-holly",
   "metadata": {},
   "source": [
    "# MOS\n",
    "\n",
    "Compute a Model Output Statistic (MOS) post-processing model for our GDPS data.\n",
    "\n",
    "MOS is recognized as a gold-standard baseline for post-processing weather forecasts.\n",
    "It's a simple linear model from predictors to the output quantity. \n",
    "In our case we will output the Gaussian distribution of temperature (so expected mean and STD).\n",
    "Our predictions will be scored using CRPS which is deemed the best way to evaluate the quality of a distribution over observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import seaborn as sns\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-accent",
   "metadata": {},
   "source": [
    "## Boot dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=['source ~/.bash_profile','conda activate smc01'],\n",
    "    name='smc01-dask',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-notification",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv('DATA_DIR'))\n",
    "INPUT_DIR = DATA_DIR / '2021-03-17-ppdataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(DATA_DIR / '2021-03-17-ppdataset/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step_hour'] = df['step'] / 3600\n",
    "df['valid'] = df['date'] + dd.to_timedelta(df['step'], unit='S')\n",
    "df['forecast_hour'] = df['date'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-tulsa",
   "metadata": {},
   "source": [
    "We will be working with only one lead time at first, say 48hrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_48 = df[df['step_hour'] == 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_48.count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-crash",
   "metadata": {},
   "source": [
    "## Build big array with 3 axis: station time feature\n",
    "\n",
    "The strategy is to iterate on the stations a build an xarray dataset for every station.\n",
    "Then we merge the xarray datasets into a big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = lead_48['station'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_to_keep = stations[stations > 1400].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_48_lots_obs = lead_48[lead_48['station'].isin(stations_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stations_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_48_lots_obs_compute = lead_48_lots_obs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [c for c in lead_48.columns if c.startswith('gdps')]\n",
    "feature_columns.append(\"obs_2t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-uncertainty",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for station in stations_to_keep:\n",
    "    station_obs = lead_48_lots_obs_compute[lead_48_lots_obs_compute['station'] == station]\n",
    "    station_obs.sort_values('date')\n",
    "        \n",
    "    features = station_obs[feature_columns].to_numpy()\n",
    "    \n",
    "    data_arrays = {}\n",
    "    for feature in feature_columns:\n",
    "        data_array = xr.DataArray(np.expand_dims(station_obs[feature].to_numpy(), axis=0), dims=['station', 'date'])\n",
    "        data_arrays[feature] = data_array\n",
    "        \n",
    "    dataset = xr.Dataset(\n",
    "        data_arrays,\n",
    "        coords={\n",
    "            'station': xr.DataArray([station], dims=['station']),\n",
    "            'date': xr.DataArray(station_obs['date'], dims=['date'])\n",
    "        })\n",
    "    \n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = xr.concat(datasets, dim='station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-linux",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged.sel(date=slice(\"2019-01-01\", \"2019-12-31\")).isnull().sum(dim=\"station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged.isnull().sum(dim='station') == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-capture",
   "metadata": {},
   "source": [
    "## Learn on a train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slice = slice(\"2019-01-01\", \"2019-12-31\")\n",
    "train_dataset = merged.drop('obs_2t').sel(date=train_slice)\n",
    "train_y = merged.obs_2t.sel(date=train_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = merged.drop('obs_2t').sel(date=slice(\"2020-01-01\", \"2020-12-31\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_dataset.to_array().transpose('station', 'date', 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOS(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mu = nn.Linear(in_features, 1, bias=True)\n",
    "        self.sigma = nn.Linear(in_features, 1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mu(x), self.sigma(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MOS(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_loss(mu_pred, sigma_pred, y_true):\n",
    "    pi = torch.Tensor([math.pi])\n",
    "    \n",
    "    \"\"\"CRPS for a Normal distribution.\"\"\"\n",
    "    loc = (mu_pred - y_true) / sigma_pred\n",
    "    phi = 1.0 / torch.sqrt(2.0 * pi) * torch.exp(-torch.square(loc) / 2.0)\n",
    "    Phi = 0.5 * (1.0 + torch.erf(loc / torch.sqrt(torch.Tensor([2.0]))))\n",
    "    \n",
    "    crps = torch.sqrt(torch.square(sigma_pred)) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / torch.sqrt(pi))\n",
    "    \n",
    "    return torch.mean(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.from_numpy(train_array.data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor[train_tensor.isnan()] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.from_numpy(train_y.data).unsqueeze(dim=-1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_hat, sigma_hat = model(train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_loss(mu_hat, sigma_hat, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_hat.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_hat.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
