{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze EMOS weights\n",
    "\n",
    "We are curious about the effect of a large forecast ID window on the rolling EMOS model.\n",
    "We hypothesize that the models with large windows will have much smoother weights through the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from smc01.postprocessing.dataset import SMCParquetDataset\n",
    "from smc01.postprocessing.util import load_checkpoint_from_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv(\"DATA_DIR\"))\n",
    "dataset_dir = DATA_DIR / 'interpolated/2021-12-20-gdps-metar/'\n",
    "dataset = SMCParquetDataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = sample.groupby('station').agg({'latitude': 'first', 'longitude': 'first', 'elevation': 'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.index[stations['station'] == 'CYUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMC01_RUNS_DIR = os.getenv(\"SMC01_RUNS_DIR\")\n",
    "if SMC01_RUNS_DIR:\n",
    "    SMC01_RUNS_DIR = pathlib.Path(SMC01_RUNS_DIR)\n",
    "    RUNS_DIR = SMC01_RUNS_DIR / 'postprocessing/multirun/2022-02-08/12-55-28/'\n",
    "else:\n",
    "    RUNS_DIR = DATA_DIR / 'runs/2022-02-08/12-55-28/'\n",
    "RUNS_BY_FILTER_SIZE = {\n",
    "    1: str(RUNS_DIR / '0'),\n",
    "    7: str(RUNS_DIR / '1'),\n",
    "    15: str(RUNS_DIR / '2'),\n",
    "    29: str(RUNS_DIR / '3'),\n",
    "    61: str(RUNS_DIR / '4'),\n",
    "    121: str(RUNS_DIR / '5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {k: load_checkpoint_from_run(RUNS_BY_FILTER_SIZE[k]) for k in RUNS_BY_FILTER_SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_biases = []\n",
    "\n",
    "filter_sizes = sorted(list(models))\n",
    "\n",
    "for s in filter_sizes:\n",
    "    m = models[s]\n",
    "    \n",
    "    data_array = xr.DataArray(\n",
    "        m.biases.squeeze().detach().numpy().reshape(1226, 365, 2, 81),\n",
    "        dims=['station', 'forecast_day', 'forecast_hour', 'lead_time'],\n",
    "        coords={\n",
    "            'station': stations['station'],\n",
    "            'lead_time': [pd.Timedelta(3*i, unit='h') for i in range(81)],\n",
    "            'forecast_hour': [pd.Timedelta(0, unit='h'), pd.Timedelta(12, unit='h')]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    model_biases.append(data_array)\n",
    "                              \n",
    "        \n",
    "biases = xr.concat(model_biases, dim='filter_size').assign_coords(filter_size=filter_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases.sel(station='CYUL').isel(lead_time=12, forecast_hour=0).plot(col='filter_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases.isel(forecast_hour=0, lead_time=24).std(dim='forecast_day').mean(dim='station').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases.isel(forecast_hour=0, lead_time=20).std(dim=['forecast_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases.std(dim=['forecast_day', 'forecast_hour', 'lead_time']).assign_coords(station=range(len(biases.station))).plot(col='filter_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = []\n",
    "filter_sizes = sorted(list(models))\n",
    "\n",
    "for s in filter_sizes:\n",
    "    m = models[s]\n",
    "    \n",
    "    data_array = xr.DataArray(\n",
    "        m.weights[..., 0].squeeze().detach().numpy().reshape(1226, 365, 2, 81),\n",
    "        dims=['station', 'forecast_day', 'forecast_hour', 'lead_time'],\n",
    "        coords={\n",
    "            'station': stations['station'],\n",
    "            'lead_time': [pd.Timedelta(3*i, unit='h') for i in range(81)],\n",
    "            'forecast_hour': [pd.Timedelta(0, unit='h'), pd.Timedelta(12, unit='h')]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    model_weights.append(data_array)\n",
    "                              \n",
    "        \n",
    "weights = xr.concat(model_weights, dim='filter_size').assign_coords(filter_size=filter_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.sel(station='CYUL').isel(lead_time=24, forecast_hour=0).plot(col='filter_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.std(dim='forecast_day').mean(dim=['station', 'lead_time', 'forecast_hour']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.sel(station='0E0').isel(forecast_hour=0, forecast_day=12).plot(col='filter_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMC01",
   "language": "python",
   "name": "smc01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
