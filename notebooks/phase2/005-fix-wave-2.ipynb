{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix ripple in error against lead time plot\n",
    "\n",
    "When plotting error against lead time for GDPS, there is a ripple in the error that is not fully explained.\n",
    "On average, we expect the error against lead time to grow monotonically.\n",
    "Thus, we would like to explain why this ripple is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(os.getenv('DATA_DIR'))\n",
    "INPUT_DATASET = DATA_DIR / 'interpolated/2021-12-20-test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = pathlib.Path(INPUT_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = next(iter(input_path.glob('*.parquet')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_parquet(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = set(sample.columns)\n",
    "columns -= set(['gdps_hpbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=['source ~/.bash_profile','conda activate smc01'],\n",
    "    name='smc01-dask',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(list(iter(input_path.glob('*.parquet'))), columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df['step_hour'] = df['step'] / 3600\n",
    "df['error_2t'] = df['obs_2t'] - df['gdps_2t']\n",
    "df['squared_error_2t'] = (df['gdps_2t'] - df['obs_2t']) ** 2\n",
    "df['rmse_2t'] = da.sqrt(df['squared_error_2t'])\n",
    "df['mabs_2t'] = np.abs(df['error_2t'])\n",
    "df['forecast_month'] = df['date'].dt.month\n",
    "df['forecast_hour'] = df['date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('date')\n",
    "df['step_td'] = dd.to_timedelta(df['step'], unit='S')\n",
    "df['valid_hour'] = (df.index + df['step_td']).dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the ripple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step_hour'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step = df.groupby(['forecast_hour', 'step_hour']).agg({'squared_error_2t': 'mean', 'index': 'count', 'valid_hour': 'mean'}).compute()\n",
    "error_by_step = error_by_step.reset_index().rename(columns={'index': 'obs_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step['rmse_2t'] = np.sqrt(error_by_step['squared_error_2t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=error_by_step, x='step_hour', y='rmse_2t', color='forecast_hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The ripple is still visible.\n",
    "* At first, the ripple is different for the 0h forecast and the 12h forecast. There is more error in the early hours of the 0h forecast at first.\n",
    "* As the lead time moves forward, the phase between both ripples disappears and both error plots seem to synchronize\n",
    "* The ripple has an amplitude of about 0.5 degree at worst.\n",
    "    * This is 5% to 25% of the total error value.\n",
    "* The ripple looks like a sinusoidal signal with a 24 h period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "\n",
    "We have a few ideas on how to explain the phenomenon. This notebook will try and validate them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An underlying wave in the observation database causes the ripple\n",
    "\n",
    "Here we suppose that there is an underlying wave in the observation signal form our database.\n",
    "The 24h period would indicate that there is a daily cycle in the qty and quality of observations we get.\n",
    "This makes sense since some stations could stop making observations at night.\n",
    "\n",
    "To fully explain the ripple, we need to show that\n",
    "\n",
    "* there is a ripple in the observation signal which matches the error ripple\n",
    "* the stations that turn on and off daily have an average error that is different from the others.\n",
    "\n",
    "In other words, our average error changes through the day because the stations we make predictions for are more difficult to predict depending on the time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step_melt = error_by_step.melt(id_vars=['forecast_hour', 'step_hour'], value_vars=['rmse_2t', 'obs_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(data_frame=error_by_step_melt, x='step_hour', y='value', facet_row='variable', color='forecast_hour', height=600)\n",
    "fig.update_yaxes(matches=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is a daily cycle of observation count.\n",
    "* The amplitude of the cycle is of about 30k observations, on a total of 1.1M. That is an amplitude of ~3% of the total signal.\n",
    "    * Can 3% of the observations provoke a variation in the error signal up to 25%?\n",
    "* There is an overall decline in the number of observations as we move through the step hours.\n",
    "    * The decline is of about 10k observations.\n",
    "    * This could be simply due to the fact that for the latest forecasts in the year, we don't have corresponding observations.\n",
    "* There seems to be a synchronization between the number of observations and the average error. \n",
    "    * The error for the 0h forecast is high when we have few observations, and high when we have more observations.\n",
    "\n",
    "Are those two different phenomenons that are both connected to the daily cycle? It seems unlikely that such a small part of the observations be responsible for such an oscillation in the error.\n",
    "I will try to measure the impact of the oscillating stations on the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midnight_forecast = df[df['forecast_hour'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step hour 6 is the through in obs, step hour 18 is close to the peak.\n",
    "hour_6_forecasts = midnight_forecast[midnight_forecast['step_hour'] == 6].groupby('station').agg({'index': 'count'}).rename(columns={'index': 'obs_count'}).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midnight_forecast['step_hour'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_18_mask = (midnight_forecast['step_hour'] > 17.0) & (midnight_forecast['step_hour'] < 19.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_18_forecasts = midnight_forecast[hour_18_mask].groupby('station').agg({'index': 'count'}).rename(columns={'index': 'obs_count'}).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_6_forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_18_forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_6_18_forecasts = hour_6_forecasts.merge(hour_18_forecasts, how='outer', on='station', suffixes=('_6h', '_18h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_6_18_forecasts['delta'] = np.abs(merged_6_18_forecasts['obs_count_18h'] - merged_6_18_forecasts['obs_count_6h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_6_18_forecasts.sort_values('delta', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_6_18_forecasts.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_6_18_forecasts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_stations = set(merged_6_18_forecasts[merged_6_18_forecasts['delta'] > 30].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving stations dataframe contains the list of stations that have a big difference in number of observation for between the peak and the trough of the n of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midnight_forecast['daily_cycle'] = midnight_forecast['station'].isin(moving_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midnight_forecast_download = midnight_forecast[['index', 'squared_error_2t', 'daily_cycle', 'step_hour', 'forecast_hour']].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step_cycle = midnight_forecast_download.groupby(['forecast_hour', 'step_hour', 'daily_cycle']).agg({'squared_error_2t': 'mean', 'index': 'count'})\n",
    "error_by_step_cycle['rmse_2t'] = np.sqrt(error_by_step_cycle['squared_error_2t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step_cycle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step_cycle = error_by_step_cycle.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step_cycle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=error_by_step_cycle, x='step_hour', y='rmse_2t', color='daily_cycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The daily ripple is still distinctly visible despite the fact that we control for stations that have a big daily cycle in observations vs those that don't.\n",
    "It seems to indicate that the variation in the underlying observations do not explain the ripple fully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 2: the average error is larger at night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyul = df[df['station'] == 'CYUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyul_error = cyul.groupby(['forecast_hour', 'step_hour']).agg({'squared_error_2t': 'mean', 'index': 'count', 'valid_hour': 'mean', 'error_2t': 'mean'}).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyul_error = cyul_error.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyul_error['rmse_2t'] = np.sqrt(cyul_error['squared_error_2t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyul.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=cyul_error, x='step_hour', y='rmse_2t', color='forecast_hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ripple seems to exist inside the station data itself. \n",
    "It seems to be harder to forecast at night than it is during the day.\n",
    "So the solution would be simply to \n",
    "- compare only values from the same step for a given station\n",
    "- aggregate the error data in bunches of 24hrs\n",
    "\n",
    "If we indeed decide to aggregate the error in bunches of 24hrs it gives something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step_td'].dt.days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step_days'] = df['step_td'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step = df.groupby(['forecast_hour', 'step_days']).agg({'squared_error_2t': 'mean', 'index': 'count', 'valid_hour': 'mean'}).compute()\n",
    "error_by_step['rmse_2t'] = np.sqrt(error_by_step['squared_error_2t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_step = error_by_step.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=error_by_step, x='step_days', y='rmse_2t', color='forecast_hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, to me this is problem solved.\n",
    "Now, that means that if the systematic biases for other variables (wind for instance) are different than that of temperature, we will need to adjust our validation graphs for that variable.\n",
    "But compensating for the diurnal cycle everywhere seems to be a good idea.\n",
    "There is also the idea of using the RPSS or something similar where we measure the average improvement over the forecast instead of the error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMC01",
   "language": "python",
   "name": "smc01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
